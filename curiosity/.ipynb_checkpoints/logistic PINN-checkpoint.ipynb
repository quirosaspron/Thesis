{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3360ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, K=100.0):\n",
    "        super().__init__() # calls the constructor of the parent class\n",
    "        self.K = K\n",
    "        \n",
    "        self.il = nn.Linear(1, 20, requires_grad=True) # Input layer, requires grad tracks the operations\n",
    "        \n",
    "        self.hl1 = nn.Linear(20, 20) # Hidden layer 1\n",
    "        self.hl2 = nn.Linear(20, 20) # Hidden layer 2\n",
    "        \n",
    "        self.ol = nn.Linear(20, 1) # Output layer\n",
    "   \n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.il(x))\n",
    "        \n",
    "        out = torch.tanh(self.hl1(out))\n",
    "        \n",
    "        out = torch.tanh(self.hl2(out))\n",
    "        \n",
    "        Z = torch.tanh(self.ol(out)) # tanh is between -1 and 1, our popluation is between 0 and K\n",
    "        \n",
    "        Y_pred = self.K / 2 * (1 + Z) # When Z is -1 we get 0, when it is 1 we get K\n",
    "        \n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(t, model, r=1.0):\n",
    "    t_physics = t.clone()\n",
    "    t_physics.requires_grad = True\n",
    "    \n",
    "    Y_pred = model(t_physics)\n",
    "    K = model.K\n",
    "    \n",
    "    # dY_dt using torch.autograd.grad\n",
    "    dY_dt = torch.autograd.grad(\n",
    "        inputs = t_physics, \n",
    "        outputs = Y_pred, \n",
    "        grad_outputs=torch.ones_like(Y_pred), \n",
    "        create_graph=True   # graph of the derivative will be constructed, allowing to compute higher order derivative products.\n",
    "    )[0]\n",
    "    \n",
    "    # the residual (f) based on the DE:\n",
    "    f =  dY_dt - (r * Y_pred * (1 - (Y_pred/K)))\n",
    "\n",
    "    \n",
    "    # MSE loss for the residual\n",
    "    loss_f = torch.mean(f**2)\n",
    "    \n",
    "    return loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_loss(model, Y0=10.0):\n",
    "    t_bc = torch.tensor([0.0]).reshape(-1, 1) \n",
    "    \n",
    "    Y_pred_bc = model(t_bc) \n",
    "    \n",
    "    Y_actual_bc = torch.tensor([Y0]).reshape(-1, 1)\n",
    "    \n",
    "    loss_bc = torch.mean((Y_pred_bc - Y_actual_bc)**2)\n",
    "    \n",
    "    return loss_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "r = 1.0        # Growth Rate\n",
    "K = 100.0      # Carrying Capacity\n",
    "Y0 = 10.0      # Initial Population\n",
    "t_min, t_max = 0.0, 10.0 # Time domain\n",
    "N_POINTS = 100 # Number of time points to enforce physics\n",
    "\n",
    "# --- Generate Training Data (Time points) ---\n",
    "t_f = torch.linspace(t_min, t_max, N_POINTS, dtype=torch.float32).reshape(-1, 1).to(DEVICE)\n",
    "\n",
    "# --- Initialize Model and Optimizer ---\n",
    "model = PINN(K=K).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10000\n",
    "\n",
    "loss_history = []\n",
    "loss_bc_history = []\n",
    "loss_f_history = []\n",
    "\n",
    "print(f\"Starting training on {DEVICE}...\")\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Calculate losses\n",
    "    # L_BC: Loss from Boundary Condition (t=0)\n",
    "    L_BC = boundary_loss(model, Y0=Y0)\n",
    "    \n",
    "    # L_F: Loss from enforcing the DE (physics)\n",
    "    L_F = physics_loss(model, t_f, r=r)\n",
    "    \n",
    "    # Total Loss\n",
    "    total_loss = L_BC + L_F\n",
    "    \n",
    "    loss_history.append(total_loss.item())\n",
    "    loss_bc_history.append(L_BC.item())\n",
    "    loss_f_history.append(L_F.item())\n",
    "    \n",
    "    # Backprop\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1:5d}/{epochs} | Total Loss: {total_loss.item():.6f} | BC Loss: {L_BC.item():.6f} | Physics Loss: {L_F.item():.6f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d938a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_history, label='Total Loss', color='red')\n",
    "plt.plot(loss_bc_history, label='Boundary Loss ($L_{BC}$)', linestyle='--')\n",
    "plt.plot(loss_f_history, label='Physics Loss ($L_F$)', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.title('PINN Loss History (Log Scale)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_solution(t, r, K, Y0):\n",
    "    return K / (1 + ((K - Y0) / Y0) * np.exp(-r * t))\n",
    "\n",
    "t_test = torch.linspace(t_min, t_max, 200, dtype=torch.float32).reshape(-1, 1).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(t_test).cpu().numpy()\n",
    "    \n",
    "    \n",
    "t_np = t_test.cpu().numpy().flatten()\n",
    "y_analytical = analytical_solution(t_np, r, K, Y0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t_np, y_analytical, label='Analytical Solution', color='black', linestyle='-')\n",
    "plt.plot(t_np, y_pred_test, label='PINN Prediction', color='red', linestyle='--')\n",
    "plt.scatter([t_min], [Y0], color='blue', label=f'Initial Condition ($Y_0$={Y0})')\n",
    "plt.axhline(K, color='green', linestyle=':', label=f'Carrying Capacity ($K$={K})')\n",
    "plt.title('PINN Solution for Logistic Growth')\n",
    "plt.xlabel('Time (t)')\n",
    "plt.ylabel('Population (Y)')\n",
    "plt.legend()\n",
    "plt.grid(True, ls=\"--\", c='0.8')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
